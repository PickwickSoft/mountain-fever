from math import ceil

import requests
from bs4 import BeautifulSoup

from quotecrawler.quotes import Quote


def category():
    """Return all relevant categories for MountainFever App

    Returns:
        list: [description]
    """
    return ["climber-quotes", "mountaineering-quotes", "mountain-quotes", "mountain-quotes", "ski-quotes", "hike-quotes", "climbing-quotes"]


def quotes(category: str, number_of_quotes: int):
    """Get a specified number of quotes for a given Category, e.g. "mountain-quotes"

    Args:
        category (str): A brainy Quote category you want to get quotes from
        number_of_quotes (int): Number of quotes you want to get. Use -1 if you want all quotes for the given category

    Returns:
        list: A list containing Quote objects
    """

    quotes_list = []

    url = "https://www.brainyquote.com/topics/" + category + ".html"
    html = requests.get(url)
    soup = BeautifulSoup(html.text, features="html.parser")

    # div id of the quotes are generated by position with the format:
    # "qpos_%page%_%element%"
    # where element <- [1, .. 26] and page <- [1..] with infinite scroll
    times = 1
    if number_of_quotes > 26:
        # Scrolling is required as there are not enough quotes in the page
        times = ceil(number_of_quotes/26)
        print("Getting %d pages..." % (times))

    x = y = n = 0
    while (n < number_of_quotes or number_of_quotes == -1):
        y = (y % 26) + 1    # List starts at 1
        if y == 1:        # New Page must be loaded
            x += 1
            # We can get each page individually with "%category%_[1..]"
            url = "https://www.brainyquote.com/topics/" + \
                category + "_" + str(x)
            html = requests.get(url)
            if n >= 1 and html.url != url:
                break
            soup = BeautifulSoup(html.text, features="html.parser")

        div_id = "pos_" + str(x) + "_" + str(y)
        find = soup.find("div", {"id": div_id})
        if find is not None:
            quote = str(find.text.split("\n\n\n", 1)[0]).split("\n")
            if len(quote) >= 3:
                quote = Quote(quote[1].replace('"', ''),
                              quote[2].replace('"', ''))
                quotes_list.append(quote)

        n += 1

    return quotes_list
